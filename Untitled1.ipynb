{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBEf1CnYhohPDUG+vqg8Ij",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samuel131200/LasActividadesVanAqui/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ARczifg4pwWo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision.utils import make_grid as vutils\n",
        "from torchvision import transforms\n",
        "from torch.optim import lr_scheduler\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import torch.optim as optim \n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "from PIL import Image\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed=42\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "device=torch.device(\"cuda\") if torch.has_cuda else torch.device(\"cpu\")\n",
        "lr=0.001\n",
        "epochs=16\n",
        "batch_size=16\n",
        "gamma = 0.5\n",
        "csv_combine = pd.read_csv(\"../input/165-different-snakes-species/Csv/train.csv\")\n",
        "csv_test = pd.read_csv(\"../input/165-different-snakes-species/Csv/test.csv\") \n",
        "image_dim = 418"
      ],
      "metadata": {
        "id": "vmjnoVoqAnCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_id = {}\n",
        "for i,cl in enumerate(csv_combine.class_id.unique()):\n",
        "    class_id[cl] = i\n",
        "nclass = i+1 "
      ],
      "metadata": {
        "id": "3AvSUdTi7a5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_train = csv_combine\n",
        "train_size = len(csv_train)\n",
        "test_size = len(csv_test)"
      ],
      "metadata": {
        "id": "gwNLnRr87m18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_train.head()"
      ],
      "metadata": {
        "id": "M1S5liai7osa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_test.head()"
      ],
      "metadata": {
        "id": "mTxBNUY372Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Species\".ljust(97)+\"No Of Images\")\n",
        "for i in csv_train.binomial.unique():\n",
        "    print(\"{} {}\".format(i.ljust(100),sum(csv_train.binomial == i)))"
      ],
      "metadata": {
        "id": "ukcSLPT673bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize']=(13,13)\n",
        "text = list(set((csv_test.binomial).unique()))\n",
        "wordcloud = WordCloud(max_font_size=40,max_words=(csv_test.binomial).unique().shape[0]).generate(str(text))\n",
        "plt.imshow(wordcloud,interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vOA2fbqI8Hkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imagefolder = ImageFolder(\"../input/165-different-snakes-species/train\", transform=transforms.ToTensor())\n",
        "# image_dataloader=DataLoader(imagefolder, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "# def batch_mean_and_sd(loader):  \n",
        "#     cnt = 0\n",
        "#     fst_moment = torch.empty(3)\n",
        "#     snd_moment = torch.empty(3)\n",
        "\n",
        "#     for images, _ in tqdm(loader):\n",
        "#         b, c, h, w = images.shape\n",
        "#         nb_pixels = b * h * w\n",
        "#         sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "#         sum_of_square = torch.sum(images ** 2,\n",
        "#                                   dim=[0, 2, 3])\n",
        "#         fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
        "#         snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
        "#         cnt += nb_pixels\n",
        "\n",
        "#     mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)        \n",
        "#     return mean,std\n",
        "\n",
        "# mean, std = batch_mean_and_sd(image_dataloader)\n",
        "#\n",
        "# calculated mean and standard deviation\n",
        "# mean = [0.4718, 0.4429, 0.3738] , Std = [0.2519, 0.2388, 0.2393]"
      ],
      "metadata": {
        "id": "Hys1hwFm8gsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformation = {\n",
        "    \"transformation_image\": transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize(size=(image_dim,image_dim)),\n",
        "            transforms.Normalize((0.4718, 0.4429, 0.3738),(0.2519, 0.2388, 0.2393))\n",
        "        ])\n",
        "}    \n",
        "\n",
        "transform_aug = transforms.Compose([\n",
        "    transforms.RandomRotation(360)\n",
        "])"
      ],
      "metadata": {
        "id": "dx7HAwOB8iY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_receiver(Dataset):\n",
        "    def __init__(self, csv, traindir, device, transform, class_id, aug = None):\n",
        "        self.csv = csv\n",
        "        self.traindir = traindir\n",
        "        self.transform =transform\n",
        "        self.device = device\n",
        "        self.class_id = class_id\n",
        "        self.aug = aug\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        csv = self.csv.iloc[[idx]]\n",
        "        cl = csv[\"class_id\"].values[0]\n",
        "        location = self.traindir + \"/\" + str(cl) + \"/\" + csv[\"UUID\"].values[0] + \".jpg\"\n",
        "        bbox = []\n",
        "        image = Image.open(location)\n",
        "        key = str(cl) + csv[\"UUID\"].values[0]\n",
        "        if self.aug != None:\n",
        "            image = self.aug(image)\n",
        "            \n",
        "        image = np.array(image)\n",
        "\n",
        "        \n",
        "        # now [x center , y center , width , height]  \n",
        "        shape = image.shape[0]\n",
        "        try:\n",
        "            x,y,width,height = [csv.X, csv.Y, csv.width, csv.height] * shape\n",
        "            x0 ,y0 = int(x-(width/2)) ,int(y-(height/2))\n",
        "            x1 ,y1 = int(x+(width/2)) ,int(y+(height/2))\n",
        "\n",
        "            if x0 < 0:\n",
        "                x0=0\n",
        "            if x1 > shape:\n",
        "                x1 = shape\n",
        "            if y0 < 0:\n",
        "                y0 = 0\n",
        "            if y1 > shape:\n",
        "                y1 = shape\n",
        "\n",
        "            processed_image = self.transform[\"transformation_image\"](image[y0:y1, x0:x1])\n",
        "            return processed_image, torch.tensor(self.class_id[cl]) \n",
        "        except:\n",
        "            processed_image = self.transform[\"transformation_image\"](image)\n",
        "            return processed_image, torch.tensor(self.class_id[cl])"
      ],
      "metadata": {
        "id": "Qdiq-FFK9Kuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_aug = Dataset_receiver(csv_train, \"../input/165-different-snakes-species/train/\", device, transformation, class_id, transform_aug)\n",
        "train_dataset_normal = Dataset_receiver(csv_train, \"../input/165-different-snakes-species/train/\", device, transformation, class_id)\n",
        "test_dataset = Dataset_receiver(csv_test, \"../input/165-different-snakes-species/test/\", device, transformation, class_id)\n",
        "\n",
        "train_dataset = train_dataset_aug + train_dataset_normal\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "ldE1hyt39So9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,_ = next(iter(train_dataloader))\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.title(\"Training Dataset\")\n",
        "plt.imshow(torch.swapdims(torch.swapdims(vutils(a,8,2),0,2),0,1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K2Be_4ux9but"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,_ = next(iter(test_dataloader))\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.title(\"Test Dataset\")\n",
        "plt.imshow(torch.swapdims(torch.swapdims(vutils(a,8,2),0,2),0,1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NWkp-EpS9o6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, verbose = 1):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train']:\n",
        "            if phase == 'train':\n",
        "                dataloaders=train_dataloader\n",
        "                model.train()  # Set model to training mode\n",
        "                dataset_sizes=train_size*2\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            if verbose == 1:\n",
        "                loop = tqdm(dataloaders)\n",
        "            else:\n",
        "                loop = dataloaders\n",
        "            for inputs, labels in loop:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item()* inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                if verbose == 1:\n",
        "                    loop.set_postfix(loss=loss.item())\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def accuracy(dataloader, model):\n",
        "    model.eval()\n",
        "    result = []\n",
        "    output = []\n",
        "    label = []\n",
        "    with torch.no_grad():\n",
        "        for i, j in tqdm(dataloader):\n",
        "            out = model(i.to(device))\n",
        "            out = out.argmax(dim = 1).to(torch.device(\"cpu\"))\n",
        "            result += (j == out).tolist()\n",
        "            output += out.tolist()\n",
        "            label += j.tolist()\n",
        "    print(\"Accuarcy Of the Test set: \",sum(result)/len(result))  \n",
        "    return output, label\n",
        "            "
      ],
      "metadata": {
        "id": "JvNko2s799hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b4', pretrained=True)\n",
        "model.classifier.fc = nn.Linear(model.classifier.fc.in_features, nclass)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=gamma)\n"
      ],
      "metadata": {
        "id": "Tt_nQTeR-tAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, criterion, optimizer, scheduler, num_epochs=epochs, verbose = 0)\n",
        "output, label = accuracy(test_dataloader, model)\n",
        "output, label = np.array(output), np.array(label)"
      ],
      "metadata": {
        "id": "x2lkMINY-vyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_name = list(class_id.values())"
      ],
      "metadata": {
        "id": "hTMOcvwk-0i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Precision_recall(label, output, class_id):\n",
        "    precision = []\n",
        "    recall = []\n",
        "    print(\"{}{}{}{}\".format(\"Label\".ljust(20), \"Accuracy\".ljust(20), \"Precision\".ljust(20), \"Recall\".ljust(20)))\n",
        "    for i in list(class_id):\n",
        "        label_truth = np.array(label) == i\n",
        "        output_truth = np.array(output) == i\n",
        "        temp_tp = label[label_truth] == output[label_truth]\n",
        "        temp_fp = sum(output_truth) - sum(label_truth * output_truth)\n",
        "        temp_fn = sum(label_truth) - sum(label_truth * output_truth)\n",
        "        p = sum(temp_tp)/((sum(temp_tp)+temp_fp) if (sum(temp_tp)+temp_fp) != 0 else 1)\n",
        "        r = sum(temp_tp)/((sum(temp_tp)+temp_fn) if (sum(temp_tp)+temp_fn) != 0 else 1)\n",
        "        precision.append(p)\n",
        "        recall.append(r)\n",
        "        print(\"{}{}{}{}\".format(str(i).ljust(20), str(sum(temp_tp)/len(temp_tp)).ljust(20), str(p).ljust(20), str(r).ljust(20)))    \n",
        "    precision = sum(precision)/len(precision)\n",
        "    recall = sum(recall)/len(recall)\n",
        "    f1_score = 2*(precision*recall)/(precision+recall)\n",
        "    print(\"F1 Score : {}\".format(f1_score))\n",
        "    return f1_score\n",
        "torch.save(model,'model_snakes.pt')"
      ],
      "metadata": {
        "id": "H_VX5_k5-3rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Precision_recall(label, output, id_name)"
      ],
      "metadata": {
        "id": "FtAtFWRX_Lre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Sa3pbUBx_MnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}